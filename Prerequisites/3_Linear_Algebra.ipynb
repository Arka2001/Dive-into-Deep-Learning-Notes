{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3 - Linear Algebra.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7SDbpj6G3T2"
      },
      "source": [
        "**LINEAR ALGEBRA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GXRIUU6G8dW"
      },
      "source": [
        "**Scalars**\n",
        "\n",
        "A scalar is aphysical quantity having technically zero dimensions. It only has magnitude and no other dimension with is. It is basically a constant numerical value. Like, 5,9,23,20, etc. are all constant scalar values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-o3rm4yGQwX"
      },
      "source": [
        "#In PyTorch scalar values are represented as a 1x1 dimension vector. Such as follows:\n",
        "import torch\n",
        "scalar1 = torch.tensor([3.0])\n",
        "scalar2 = torch.tensor([4.0])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8qf6SQqKzSY",
        "outputId": "9540e572-6ba3-49ef-fb61-22aa7b41e349"
      },
      "source": [
        "scalar1+scalar2, scalar1-scalar2,scalar1*scalar2,scalar1/scalar2,scalar1//scalar2,scalar1**scalar2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([7.]),\n",
              " tensor([-1.]),\n",
              " tensor([12.]),\n",
              " tensor([0.7500]),\n",
              " tensor([0.]),\n",
              " tensor([81.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL06QsPYRjVR"
      },
      "source": [
        "**Vectors**\n",
        "\n",
        "Vectors are simply one-dimensional quantities. To put it in a more simple manner, we can consider a vector to be a list of values. For example, [1,2,3,4] is considered as a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2A22bF9ROXy",
        "outputId": "5df56052-8561-4aea-aa28-a9d29168cc53"
      },
      "source": [
        "#Using, PyTorch a vector can be easily created using the arange command.\n",
        "vector = torch.arange(10)\n",
        "vector"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "406mqqOjSINg",
        "outputId": "1944054d-0a10-4905-cc9e-e3edf73e0caa"
      },
      "source": [
        "#Any element of the vector can be accessed through the index of that vector. For instance in this case, the index for 2 is 2.\n",
        "vector[2]  #<- vector_name[index of element]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSTc9-NZSZO1",
        "outputId": "bb07c7de-0ab1-4db7-8565-693fbfc91fb5"
      },
      "source": [
        "#Length of a vector can be found by the inbuilt len() function in Python\n",
        "len(vector)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q69scHqnSyQN",
        "outputId": "63790623-c8bb-4bc2-c521-4506d3d3b765"
      },
      "source": [
        "#To get the shape of the vector you can use the .shape function\n",
        "vector.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pljYXPRXg6z"
      },
      "source": [
        "**Matrices**\n",
        "\n",
        "Just like One-dimensional tensors are called vectors, similarly, two-dimensional tensors are called matrices. Matrices can be created by first creating a vector and then by reshaping it. A matrix contains 2 dimensions, x and y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ODFIPhZXcU1",
        "outputId": "c1f3aa4d-a7ef-400e-c9d5-5b6675338a10"
      },
      "source": [
        "matrix = torch.arange(20).reshape(5,4)\n",
        "matrix"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15],\n",
              "        [16, 17, 18, 19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxZoBV1pZZna",
        "outputId": "acc5c25f-5a16-4549-b387-a29479058465"
      },
      "source": [
        "'''Elements of a matrix can also be accessed through indexing.\n",
        "But in contrary to indexing in a vector, which requires only one index, indexing in a matrix requires 2 indices, one for the row and one for the column.\n",
        "For example, if we want the element at row of index 2 and column of index 3 of the matrix mat, we would have to write mat[2][3] to get the element.\n",
        "'''\n",
        "\n",
        "matrix[2][3]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcr_Fl1RedOK"
      },
      "source": [
        "The transpose of a matrix is when the columns and the rows interchange with each other. Say for instance we have a matrix '[[1,2],[3,4]]'. The transpose of this matrix would be '[[1,3],[2,4]]'. Notice that the elements of the primary diagonal, in this case 1 and 4 do not change their places. When writing code we can easily find the transpose of any given matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zVkqsCpdeky",
        "outputId": "00ee8821-0ca2-403c-a254-1cd123b2ddab"
      },
      "source": [
        "#Transpose of matrix is given by\n",
        "matrix.T"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  4,  8, 12, 16],\n",
              "        [ 1,  5,  9, 13, 17],\n",
              "        [ 2,  6, 10, 14, 18],\n",
              "        [ 3,  7, 11, 15, 19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSKYe4NFgxXr"
      },
      "source": [
        "For a *symmetric* matrix, the transpose of the matrix is equal to the original matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwdvO3NifBg1",
        "outputId": "4fb0724b-416e-4d0d-9028-f29a111c6d0a"
      },
      "source": [
        "#Let us define a symmetric matrix A\n",
        "A = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\n",
        "A"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [2, 0, 4],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mRqxJughtJD",
        "outputId": "a28ef710-1498-4c33-e702-9f7656c47f14"
      },
      "source": [
        "#Let B be the transpose of A\n",
        "B = A.T\n",
        "B"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [2, 0, 4],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVOSq9gphztM"
      },
      "source": [
        "As you can see that there is no difference between matrices B and A. We can also prove it by the following command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfwnR1gLhyT0",
        "outputId": "5680f0fc-71fd-4a9d-adc6-3430a2ca600f"
      },
      "source": [
        "A == B"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBcH7h5vh8Ka"
      },
      "source": [
        "Therefore we see that for a symmetric matrix A, A.T = A. Inversely, we can say that a matrix whose transpose is equal to that matrix itself is a **symmetric** matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBViS-CbnOuH"
      },
      "source": [
        "**Tensors**\n",
        "\n",
        "Tensor is the general term for any dimensional array. One-dimensional tensors are called vectors, two-dimensional tensors are called matrices. Any higher order tensors do not have any specific names, they are simply called tensors. Tensors in PyTorch can be created using the torch.tensor() function. We can also create a vetor using the arange() function and then reshape it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoXzLzDKh60x",
        "outputId": "a99c9128-d0f7-41fa-fcb9-5bc34373e2de"
      },
      "source": [
        "A = torch.arange(24).reshape(2,3,4)\n",
        "A"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwX1W2U-pDWD"
      },
      "source": [
        "Anything beyond 3 dimensions is very difficult for us to imagine. But using numpy and PyTorch tensors, we can work with and manipulate n-dimensional tensors or arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsmaBM47qaCS"
      },
      "source": [
        "**Tensor Arithmetic - Basics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUo8Ars2rhs4"
      },
      "source": [
        "Any n-dimensional tensor has a lot of functionalities which can be used for our benefit. Most important of these functionalities are the elementwise arithmetic operations between two tensors of the shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8qb4hSSo9Na"
      },
      "source": [
        "A = torch.arange(20).reshape(4,5)\n",
        "B = torch.arange(3,23).reshape(4,5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meLI0YHMterc",
        "outputId": "caab3df0-fa17-4e1d-9053-ea335e2624f7"
      },
      "source": [
        "A"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3,  4],\n",
              "        [ 5,  6,  7,  8,  9],\n",
              "        [10, 11, 12, 13, 14],\n",
              "        [15, 16, 17, 18, 19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ-xvCZmtiTx",
        "outputId": "0e2123fa-addb-40ff-ed5c-bc0409f01830"
      },
      "source": [
        "B"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3,  4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11, 12],\n",
              "        [13, 14, 15, 16, 17],\n",
              "        [18, 19, 20, 21, 22]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UMolr6mtjWi",
        "outputId": "ea0f705f-7473-40d3-b737-8b1830754957"
      },
      "source": [
        "A+B"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3,  5,  7,  9, 11],\n",
              "        [13, 15, 17, 19, 21],\n",
              "        [23, 25, 27, 29, 31],\n",
              "        [33, 35, 37, 39, 41]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_CNoyJPtqiI"
      },
      "source": [
        "Usually, we do not do elementwise multiplication of two tensors or rather matrices. The elementwise multiplication of two matrices is called *Hadamard* multiplication.\n",
        "\n",
        "**Note: Make sure that whenever you perform elementwise operations on 2 matrices, the shpae of the matrices should be equal.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlkhf4XVtlCI",
        "outputId": "49b5d645-a366-4904-c3ea-7bd757800250"
      },
      "source": [
        "A*B #Hadamard multiplication"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   4,  10,  18,  28],\n",
              "        [ 40,  54,  70,  88, 108],\n",
              "        [130, 154, 180, 208, 238],\n",
              "        [270, 304, 340, 378, 418]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H_vnvs8G8g8"
      },
      "source": [
        "Multiplying or adding a tensor with a scalar quantity does not change the shape of the tensor. Rather each element of the tensor gets added or multiplied with the scalar quantity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJcmg7pwzL24",
        "outputId": "ad8ce344-687f-462c-bf9b-bb2cc948e7f6"
      },
      "source": [
        "a = 5\n",
        "A = torch.arange(9).reshape(3,3)\n",
        "A"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5],\n",
              "        [6, 7, 8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9lhOb_NHtVL",
        "outputId": "2e5b00d1-c172-4111-bd43-7c0b02e6eb31"
      },
      "source": [
        "a + A"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5,  6,  7],\n",
              "        [ 8,  9, 10],\n",
              "        [11, 12, 13]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iocFsbcuHw55",
        "outputId": "c8d1f2ac-1fff-46df-8056-7d5eb6adb80f"
      },
      "source": [
        "a * A"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  5, 10],\n",
              "        [15, 20, 25],\n",
              "        [30, 35, 40]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43W1IZdAJjRP"
      },
      "source": [
        "**Reduction**\n",
        "\n",
        "Using tensors in Python can help us reduce our code and therefore increase efficiency. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czMYYrmBH0Ah",
        "outputId": "a1b6351d-e4e3-4002-a656-dbbdc31d08fa"
      },
      "source": [
        "#We can find the sum of all elements in a tensor through the .sum() function\n",
        "X = torch.arange(4,dtype=torch.float32)\n",
        "X,X.sum()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3.]), tensor(6.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JwcPMwlKdeG",
        "outputId": "924f7b7e-9403-4488-8733-fd5a3b056316"
      },
      "source": [
        "A = torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
        "A.shape,A.sum()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), tensor(190.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdoADmKIKulR"
      },
      "source": [
        "As we can see from the above cells and their outputs, the .sum() function reduces the original tensor to a one-dimensional vector. Therefore using this functionality, we can calculate the sum of elements in each row or column of the tensor, by specifying the axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ05kgcjKsEs",
        "outputId": "694197a7-9a09-465e-ec76-659661f575da"
      },
      "source": [
        "A"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.],\n",
              "        [12., 13., 14., 15.],\n",
              "        [16., 17., 18., 19.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOgzXgr7Lwfx",
        "outputId": "82c2e457-b8f8-4d19-d11c-0539d7762eff"
      },
      "source": [
        "sum_each_row = A.sum(axis=0) #Code for finding the sum of elements of each row\n",
        "sum_each_row"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([40., 45., 50., 55.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY6qvhooMDNb",
        "outputId": "9cd168ab-6e05-453a-9b89-44a7357b51dc"
      },
      "source": [
        "sum_each_col = A.sum(axis=1) #Code for finding the sum of elements of each column\n",
        "sum_each_col"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6., 22., 38., 54., 70.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-G20BMjMr_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab164cb4-3def-4dc2-da64-a5bbe0da1e4c"
      },
      "source": [
        "#Finding the mean of all elements in the tensor\n",
        "A.mean(), A.sum()/A.numel()   #.numel() function returns the total number of elements present in the tensor"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9.5000), tensor(9.5000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1mK7flwuQyh",
        "outputId": "99047bc6-a7dc-47ea-b948-942d1fed1504"
      },
      "source": [
        "#Finding mean of elements present in along an axis, say mean of elements of each row\n",
        "A.mean(axis=0),A.sum(axis=0)/A.shape[0] #.shape[0] returns the number of rows in the tensor, or rather the number of elements in each column"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xojjBEdevAxJ"
      },
      "source": [
        "**Non-Reduction Sum**\n",
        "\n",
        "Many a times, it would be helpful for you if you do not reduce the dimensions of the given tensor while finding the sum of all the elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trazg_5nuxth",
        "outputId": "d6a0d96e-ce24-42cb-84ae-9bda1a196ff6"
      },
      "source": [
        "#How to keep the dimensions same, i.e., find the non-reduction sum?\n",
        "\n",
        "A_sum = A.sum(axis = 1,keepdims=True)\n",
        "A_sum"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.],\n",
              "        [22.],\n",
              "        [38.],\n",
              "        [54.],\n",
              "        [70.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLX7jvb-w4Yi",
        "outputId": "475be991-9f23-4a4e-b42b-0bb2cb13d6f6"
      },
      "source": [
        "A/A_sum"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
              "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
              "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
              "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
              "        [0.2286, 0.2429, 0.2571, 0.2714]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaCMkB2GxSrS",
        "outputId": "7223504f-5584-4698-ed75-ee784b2801ca"
      },
      "source": [
        "A.cumsum(axis=0) #Function to calculate the elementwise cumulative sum of the tensor. This does not reduce the dimensions of the tensor"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  6.,  8., 10.],\n",
              "        [12., 15., 18., 21.],\n",
              "        [24., 28., 32., 36.],\n",
              "        [40., 45., 50., 55.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POH2vxPrzSH0"
      },
      "source": [
        "**Dot Products**\n",
        "\n",
        "Dot product is an integral part of Linear Algebra. Now what is dot product. Dot product of two tensors means the sum of the products of all the elements at the same positions at the two tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PekTIh6fye_y",
        "outputId": "7d6fcf0d-80e8-45e6-ece2-50bd9145b29d"
      },
      "source": [
        "x = torch.arange(4)\n",
        "y = torch.arange(5,9)\n",
        "x,y,torch.dot(x,y)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3]), tensor([5, 6, 7, 8]), tensor(44))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBlXqyYd04nG",
        "outputId": "80eb9da6-17b1-4545-ffda-091c197f18f6"
      },
      "source": [
        "#Instead of the dot() function we can first perform elementwise multiplication operation and then find out the sum of the resultant tensor\\\n",
        "x*y,torch.sum(x*y)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  6, 14, 24]), tensor(44))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYUAE2d-1f4Q"
      },
      "source": [
        "**Matrix Vector Operations**\n",
        "\n",
        "Using dot products, we can find the length of a resultant tensor of any two tensors. But using vector operations, we can get the magnitude as well as the other necessary dimensions required for a tensor. This is mopstly prevalent in matrices, because, matrices contain 2 dimensions, directions and magnitudes. Therefore using vector operations on any 2 matrices, we can get a resultant matrix, which will give us the direction and magnitude. In this section we are going to deal with products between a matrix and a vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5kgmLgY1SSh",
        "outputId": "5ee2ebbb-3896-43a0-c5ed-ba99d72f00d3"
      },
      "source": [
        "A #Matrix"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.],\n",
              "        [12., 13., 14., 15.],\n",
              "        [16., 17., 18., 19.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzpHuqqK50b8",
        "outputId": "1661d5cb-089a-490d-978f-1d95ae79c0a1"
      },
      "source": [
        "x = torch.arange(4,dtype=torch.float32)#Vector\n",
        "x"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f842mj5z54ew",
        "outputId": "35baf2a6-07b0-41c3-c0cb-f32b00c9fbf8"
      },
      "source": [
        "A.shape,x.shape,torch.mv(A,x)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2d0ggf9L-Wh"
      },
      "source": [
        "**Matrix-Matrix Multiplication**\n",
        "\n",
        "This is also known as matrix multiplication. The process of matrix multiplication is that if we are multiplying A*B, then each element of the first row of the resultant matrix is the sum of the products of corresponding elements in the first row of A and the corresponding numbered column of B. Similarly, each element of the second row of the resultant matrix is the sum of products of corresponding elements in second row of A and the corresponding numbered column of B.\n",
        "\n",
        "Say, for instance, A = [[1,2,3],\n",
        "\n",
        "[4,5,6],\n",
        "\n",
        "[7,8,9]] \n",
        "\n",
        "and B = [[1,1,1]\n",
        "\n",
        ",[2,2,2],\n",
        "\n",
        "[3,3,3]]\n",
        "\n",
        "Therefore AxB = \n",
        "\n",
        "[[1x1+2x2+3x3,1x1+2x2+3x3,1x1+2x2+3x3],\n",
        "\n",
        "[4x1+5x2+6x3,4x1+5x2+6x3,4x1+5x2+6x3,],\n",
        "\n",
        "[7x1+8x2+9x3,7x1+8x2+9x3,7x1+8x2+9x3]]\n",
        "\n",
        "= [[14,14,14],\n",
        "\n",
        "[32,32,32],\n",
        "\n",
        "[50,50,50]]\n",
        "\n",
        "One more thing to keep in mind is that for 2 vectors, if a matrix A has a shape nxm and matrix B has a shape mxp, then the resultant matrix AxB shall have a shape of nxp\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyjm3m83CtVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037b7f0a-43a5-4eed-ed10-f0f69287d495"
      },
      "source": [
        "A"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.],\n",
              "        [12., 13., 14., 15.],\n",
              "        [16., 17., 18., 19.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1L3tbSyH1zw",
        "outputId": "02bbc975-785d-4ed5-eefd-184956f9c017"
      },
      "source": [
        "B = torch.ones(4,3)\r\n",
        "B"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_G4abyHH6Oh",
        "outputId": "86a01721-625b-4fc2-ae25-e2475b961b4f"
      },
      "source": [
        "torch.mm(A,B)  #np.dot(A,B)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.,  6.,  6.],\n",
              "        [22., 22., 22.],\n",
              "        [38., 38., 38.],\n",
              "        [54., 54., 54.],\n",
              "        [70., 70., 70.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96jdM2PxVsUX"
      },
      "source": [
        "**NORM**\r\n",
        "\r\n",
        "The norm of a vector or a matrix is of 2 types. One is the L1 norm and the other is the L2 norm. \r\n",
        "\r\n",
        "The L1 norm is the sum of the absolute values of all the elements present in the vector or matrix.\r\n",
        "\r\n",
        "The L2 norm is the sum of the squares of all the elements present in the vector or matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siifuoCRIHl5",
        "outputId": "b2217b4a-d94c-4082-9b88-beeb7825342a"
      },
      "source": [
        "#L2 Norm\r\n",
        "\r\n",
        "x = torch.tensor([3.0,-4.0])     # np.array([3.0,-4.0])\r\n",
        "torch.norm(x)   #np.linalg.norm(x)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBm3OFk4Xwhq",
        "outputId": "864d1ad5-91d4-4e1e-eee4-c20ff0cde582"
      },
      "source": [
        "#L1 Norm\r\n",
        "\r\n",
        "torch.abs(x).sum()  #np.abs(x).sum()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wewK6P9-X7id"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}